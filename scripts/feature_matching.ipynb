{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aace9f1-dc96-46ae-a094-2a972b362102",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm opencv-contrib-python matplotlib numpy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb77ef39-c0db-4486-b0e9-d6379f1c4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20398c86-3057-4789-b702-2917e415d564",
   "metadata": {},
   "source": [
    "# Prepare the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9039a1e7-342c-4261-86c7-ad54b70615c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found. Proceeding with feature matching...\n"
     ]
    }
   ],
   "source": [
    "# Dataset directory path\n",
    "DATASET_DIR = \"./brandenburg_gate\"\n",
    "\n",
    "# Check if the dataset directory exists\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    print(\"Dataset directory not found. Please make sure the dataset is already extracted.\")\n",
    "else:\n",
    "    print(\"Dataset found. Proceeding with feature matching...\")\n",
    "\n",
    "# load the image pairs\n",
    "image_files = [os.path.join(DATASET_DIR, f) for f in os.listdir(DATASET_DIR) if f.endswith('.jpg')]\n",
    "image_pairs = [(image_files[i], image_files[i + 1]) for i in range(0, min(len(image_files) - 1, 100), 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52e0be-6129-486f-8cd5-d151ebc8bf62",
   "metadata": {},
   "source": [
    "# Feature Detection and Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fb1833-b875-44c0-83e8-cc3ee65af713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features_and_error(img1_path, img2_path, method=\"SIFT\", matcher_type=\"BF\", visualize=False):\n",
    "    img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img1 is None or img2 is None:\n",
    "        return None, None\n",
    "\n",
    "    if method == \"SIFT\":\n",
    "        feature_extractor = cv2.SIFT_create()\n",
    "    elif method == \"ORB\":\n",
    "        feature_extractor = cv2.ORB_create()\n",
    "    elif method == \"AKAZE\":\n",
    "        feature_extractor = cv2.AKAZE_create()\n",
    "    elif method == \"BRISK\":\n",
    "        feature_extractor = cv2.BRISK_create()\n",
    "    elif method == \"KAZE\":\n",
    "        feature_extractor = cv2.KAZE_create()\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "    keypoints1, descriptors1 = feature_extractor.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = feature_extractor.detectAndCompute(img2, None)\n",
    "\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return None, None\n",
    "\n",
    "    if matcher_type == \"BF\":\n",
    "        matcher = cv2.BFMatcher()\n",
    "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    elif matcher_type == \"FLANN\":\n",
    "        if descriptors1.dtype != np.float32:\n",
    "            descriptors1 = np.float32(descriptors1)\n",
    "            descriptors2 = np.float32(descriptors2)\n",
    "        index_params = dict(algorithm=1, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "\n",
    "    if len(good_matches) < 4:\n",
    "        return len(good_matches), None\n",
    "\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    if H is not None:\n",
    "        projected_pts = cv2.perspectiveTransform(src_pts, H)\n",
    "        error = np.sqrt(np.sum((projected_pts - dst_pts) ** 2, axis=2)).mean()\n",
    "    else:\n",
    "        error = None\n",
    "\n",
    "    return len(good_matches), error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55552ee4-fc52-49f6-9230-096080893db0",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d21cce-a54b-48b3-b574-03b33a3c302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Features:  26%|██▌       | 13/50 [00:32<01:28,  2.39s/it]"
     ]
    }
   ],
   "source": [
    "results = {\"method\": [], \"matcher_type\": [], \"matches\": [], \"error\": []}\n",
    "\n",
    "for img1_path, img2_path in tqdm(image_pairs, desc=\"Matching Features\"):\n",
    "    for method in [\"SIFT\", \"ORB\", \"AKAZE\", \"BRISK\", \"KAZE\"]:\n",
    "        for matcher_type in [\"BF\", \"FLANN\"]:\n",
    "            matches, error = match_features_and_error(img1_path, img2_path, method, matcher_type)\n",
    "            if matches is not None:\n",
    "                results[\"method\"].append(method)\n",
    "                results[\"matcher_type\"].append(matcher_type)\n",
    "                results[\"matches\"].append(matches)\n",
    "                results[\"error\"].append(error if error is not None else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c0d78-e8a2-4106-a05b-e852e411f3ea",
   "metadata": {},
   "source": [
    "# Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d94dc2-f3fb-43d6-b7d5-737882e0542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = [\"SIFT\", \"ORB\", \"AKAZE\", \"BRISK\", \"KAZE\"]\n",
    "avg_errors = {method: {\"BF\": 0, \"FLANN\": 0} for method in detectors}\n",
    "avg_matches = {method: {\"BF\": 0, \"FLANN\": 0} for method in detectors}\n",
    "count = {method: {\"BF\": 0, \"FLANN\": 0} for method in detectors}\n",
    "\n",
    "for method, matcher, matches, error in zip(results[\"method\"], results[\"matcher_type\"], results[\"matches\"], results[\"error\"]):\n",
    "    avg_errors[method][matcher] += error if not np.isnan(error) else 0\n",
    "    avg_matches[method][matcher] += matches\n",
    "    count[method][matcher] += 1\n",
    "\n",
    "for method in detectors:\n",
    "    for matcher in [\"BF\", \"FLANN\"]:\n",
    "        if count[method][matcher] > 0:\n",
    "            avg_errors[method][matcher] /= count[method][matcher]\n",
    "            avg_matches[method][matcher] /= count[method][matcher]\n",
    "\n",
    "print(\"\\nAverage Results:\")\n",
    "for method in detectors:\n",
    "    for matcher in [\"BF\", \"FLANN\"]:\n",
    "        print(f\"Method: {method}, Matcher: {matcher}, Avg Matches: {avg_matches[method][matcher]:.2f}, Avg Error: {avg_errors[method][matcher]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07551dad-f1b4-4705-83a9-4520f56ebe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "x = np.arange(len(detectors))\n",
    "width = 0.35\n",
    "\n",
    "errors_bf = [avg_errors[method][\"BF\"] for method in detectors]\n",
    "errors_flann = [avg_errors[method][\"FLANN\"] for method in detectors]\n",
    "ax[0].bar(x - width/2, errors_bf, width, label='BF')\n",
    "ax[0].bar(x + width/2, errors_flann, width, label='FLANN')\n",
    "ax[0].set_ylabel('Average Reprojection Error (pixels)')\n",
    "ax[0].set_title('Average Reprojection Error by Detector & Matcher')\n",
    "ax[0].set_xticks(x)\n",
    "ax[0].set_xticklabels(detectors)\n",
    "ax[0].legend()\n",
    "\n",
    "matches_bf = [avg_matches[method][\"BF\"] for method in detectors]\n",
    "matches_flann = [avg_matches[method][\"FLANN\"] for method in detectors]\n",
    "ax[1].bar(x - width/2, matches_bf, width, label='BF')\n",
    "ax[1].bar(x + width/2, matches_flann, width, label='FLANN')\n",
    "ax[1].set_ylabel('Average Number of Matches')\n",
    "ax[1].set_title('Average Number of Matches by Detector & Matcher')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(detectors)\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
